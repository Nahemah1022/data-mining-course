# Project2 : Classification

###### tags: `Data Mining`

## ç¨‹å¼åŸ·è¡Œ
### ç”Ÿæˆè³‡æ–™é›†
```
python abs_generator.py
```

### åˆ†é¡
```
python classify.py
```

---

**ğŸ“ˆ åˆ†ææµç¨‹ï¼š**
åœ¨æœ¬æ¬¡å°ˆæ¡ˆä¸­ï¼Œæˆ‘å°‡è¨­è¨ˆä¸€å¥— absolutely right rule å»ç”¢å‡ºè¶³é‡çš„è³‡æ–™ï¼Œä¸¦é¸æ“‡ [scikit-learn](https://scikit-learn.org/) ç•¶ä¸­æä¾›çš„æ•¸ç¨® classifier å»å°è³‡æ–™åšåˆ†é¡ï¼Œå†ä¾æ“š classifier çš„æº–ç¢ºç‡è¡¨ç¾ä¾†å›é ­èª¿æ•´ rule ä¸­çš„å„ç¨®å±¬æ€§ï¼Œç”±æ­¤åˆ†æé€™äº› classifier åœ¨é¢å°å„ç¨®å±¬æ€§çš„è³‡æ–™æ™‚çš„é©é…æ€§ã€‚

## ä¸€ã€Absolutely Right Rules

é‡å°é€™æ¬¡å°ˆæ¡ˆï¼Œæˆ‘æ‰€è¨­è¨ˆçš„ absolutely right rule æ˜¯åƒè€ƒå°ç£çš„[å…µå½¹å¾µå¬è¦å‰‡](https://mms.taichung.gov.tw/Newsoldier/List_2)ï¼Œå…¶ä¸­ç‚ºæˆå¹´ç”·æ€§çš„å¤šé …èº«é«”æ•¸å€¼å®šç¾©äº†å…å½¹çš„åˆ¤å®šæŒ‡æ¨™ï¼Œæˆ‘å¾ä¸­æŒ‘é¸äº†å¹¾å€‹è¼ƒå…·æœ‰ä»£è¡¨æ€§çš„æŒ‡æ¨™ä¾†çµ„æˆ absolutely right ruleï¼Œ**åªè¦ä»»ä¸€æŒ‡æ¨™æœªé€šéåŠç¬¦åˆå…å½¹è³‡æ ¼**ï¼Œè¦å‰‡å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼ˆä»¥ä¸‹ç°¡ç¨±ç‚º base ruleï¼‰ï¼š

|          | èº«é«˜           | è¦–åŠ›         | æ™ºèƒ½ | æ‰å¹³è¶³          | æ°£èƒ¸   | å¿ƒå¾‹ä¸æ•´ | è‡ªé–‰ç—‡ |
| -------- | -------------- | ------------ | ------ | ------------- | ------ | -------- | ------ |
| æ•¸å€¼ç¯„åœ | 140~220 | 2.0~0 | 180~60 | 0 or 1 | 0 or 1 | 0 or 1   | 0 or 1 |
| å½¹ç”·æ¢ä»¶ | 155<x1<196 | x2 > 0.1     | x3 > 85 | x4 = 0 | x5 = 0 | x6 = 0   | x7 = 0 |

ç”±æ­¤ base rule å»ç”¢ç”Ÿå½¹ç”·/å…å½¹ (positive/negitive) è³‡æ–™ç´„å„åŠçš„ datasetï¼Œç”¨ `pandas.DataFrame.describe()` çš„æ ¼å¼å¤§è‡´å¦‚ä¸‹ï¼š

```shell
$ python abs_gengrator.py

      col_0  col_1  col_2  col_3  col_4  col_5  col_6  Y
0       184    0.7    115      0      0      0      0  1
1       219    0.4     68      0      0      0      0  0
2       212    1.8    164      0      0      0      0  0
3       193    1.0    125      0      0      0      0  1
4       186    0.1    110      0      0      0      0  1
...     ...    ...    ...    ...    ...    ...    ... ..
9995    165    1.3    177      0      0      0      0  1
9996    183    1.0    146      0      0      0      0  1
9997    179    1.1    136      0      0      0      0  1
9998    172    1.7    112      0      0      0      0  1
9999    172    0.8    160      0      0      0      0  1

[10000 rows x 8 columns]
```

## äºŒã€Classifiers

é¸ç”¨ä»¥ä¸‹å…«ç¨® [scikit-learn](https://scikit-learn.org/) æä¾›çš„ classifierï¼Œä¸¦å°‡ä¸Šè¿°ç”¢ç”Ÿçš„è³‡æ–™ 80% åšç‚º training dataã€20% ä½œç‚º testing dataï¼Œæ•ˆæœå¦‚ä¸‹ï¼š

|                     | Hyperparameters                              | Accuracy(training/testing) |
| ------------------- | -------------------------------------------- | -------------------------- |
| K Nearest Neighbors | k = 3                                        | 0.98/0.99                  |
| Decision Tree       | max_depth = 5                                | 1.00/1.00                  |
| Random Forest       | max_depth=5, n_estimators=10, max_features=1 | 1.00/1.00                  |
| Naive Bayes         |                                              | 0.89/0.84                  |
| Linear SVM          | C=0.0025                                     | 0.63/0.65                  |


å¯ä»¥çœ‹å‡ºå¤§éƒ¨åˆ† classifier çš„è¡¨ç¾å„æœ‰å„ªåŠ£ï¼Œä»¥ä¸‹å°‡é€ä¸€æ¢ç©¶æ¯å€‹ classifier åœ¨é€™å€‹ dataset ä¸Šè¡¨ç¾å¾—å¥½/å£ä¹‹åŸå› ï¼Œä¸¦æœƒå˜—è©¦ä¿®æ”¹ base ruleã€é‡æ–°ç”Ÿæˆä¸åŒå±¬æ€§çš„ dataset å¾Œå†æ¸¬è©¦ä¾†é©—è­‰åŸå› æ˜¯å¦æ­£ç¢ºã€‚

### 1. K Nearest Neighbors (KNN)

KNN æœƒæ‰¾å‡ºèˆ‡å…¶æœ€è¿‘çš„ K å€‹è³‡æ–™é»ä¾†å…±åŒæ±ºå®šè³‡æ–™é¡åˆ¥ï¼Œå› æ­¤åœ¨ç©ºé–“ä¸­**åŒé¡åˆ¥è³‡æ–™çš„åˆ†ä½ˆè¶Šå¯†é›†ï¼ŒKNN çš„è¡¨ç¾å°±æœƒè¶Šå¥½**ï¼Œè€Œå› ç‚º base rule æ‰€ç”¢ç”Ÿçš„è³‡æ–™é¡åˆ¥å¿…å®šæ˜¯åˆ‡ç¢ºçš„(deterministic)ï¼Œæœƒç›´æ¥å°‡è³‡æ–™ç©ºé–“ä¸€åˆ†ç‚ºäºŒï¼Œæ‰€ä»¥åªè¦è³‡æ–™æ¶µè“‹åº¦è¶³å¤ ï¼ŒKNN çš„è¡¨ç¾å‹¢å¿…æœƒç›¸ç•¶ä¸éŒ¯ï¼Œåªæœ‰åœ¨é è¿‘é‚Šç•Œè™•æ‰æœƒå‡ºç¾èª¤åˆ¤ã€‚
ç„¶è€Œ KNN çš„ç¼ºé»åœ¨æ–¼**ç„¡æ³•åˆ¤æ–· attribute çš„é‡è¦ç¨‹åº¦**ï¼Œè‹¥æœ‰èˆ‡ classifaction rule å®Œå…¨ç„¡é—œ (irrelevant) çš„ attribute å­˜åœ¨ï¼ŒKNN ä¹ŸæœƒæŠŠè³‡æ–™åœ¨é€™å€‹ç¶­åº¦ä¸Šçš„è·é›¢è¦–ä½œèˆ‡å…¶ä»–é‡é» attributes åŒç­‰é‡è¦çš„è³‡è¨Šï¼Œé€²è€Œé€ æˆèª¤åˆ¤ï¼Œä»¥ä¸‹å°‡å¯¦é©—æ’å…¥ 7 å€‹æ•¸å€¼å®Œå…¨éš¨æ©Ÿçš„ attributes å¾Œå° accuracy çš„å½±éŸ¿ã€‚

```shell
$ python abs_generator.py --irrelevant 7


      col_0  col_1  col_2  col_3  col_4  ...  col_10  col_11  col_12  col_13  Y
0       186    0.7     76      0      0  ...       5     121      17     144  0
1       176    0.1    155      0      0  ...      69     174      96      69  1
2       210    1.1    117      0      0  ...     156      66     183     183  0
3       197    0.8    133      0      0  ...     168     143       6     118  0
4       175    0.5    162      0      0  ...      84      28      90      88  1
...     ...    ...    ...    ...    ...  ...     ...     ...     ...     ... ..
9995    156    1.4    179      0      0  ...      80     169      10       5  1
9996    155    0.3    114      0      0  ...     112       8     180      30  1
9997    196    1.5    107      0      0  ...      87      51      28     133  1
9998    187    1.3    165      0      0  ...     157      49     167      67  1
9999    157    0.1    178      0      0  ...      70      73      16     145  1
```
å¦‚ä¸Šæ‰€ç¤ºï¼Œ`col_7` åˆ° `col_13` æ˜¯èˆ‡ base rule å®Œå…¨ç„¡é—œçš„äº‚æ•¸ï¼Œåœ¨æ­¤ dataset ä¸­ KNN çš„è¡¨ç¾å¦‚ä¸‹ï¼š
- training data accuracy: 0.82
- testing data accuracy: 0.69

çœ‹å¾—å‡ºä¾†æ¯”åŸå…ˆä¸‹é™äº†ä¸å°‘ï¼Œç”±æ­¤å¯çŸ¥ KNN ä¸æ“…é•·è™•ç†å­˜åœ¨ irrelevant attributes çš„ datasetã€‚

---

### 2. Decision Tree

Decision tree æ˜¯é€éé¸å®šæŸå€‹ attribute çš„å€¼ä½œç‚ºåˆ†æ­§é»ï¼Œä¾†ä½¿è³‡æ–™é¡åˆ¥ç›¡å¯èƒ½è¢«ä¸€åˆ†ç‚ºäºŒçš„æ¼”ç®—æ³•ï¼Œæ›å¥è©±èªªï¼Œ**åªè¦è³‡æ–™é¡åˆ¥æœ‰è¾¦æ³•è¢«æŸå€‹ attribute çš„å€¼å®Œå…¨ä¸€åˆ†ç‚ºäºŒï¼Œdecision tree å°±å¯ä»¥åšåˆ° 100% çš„æº–ç¢ºç‡**ï¼Œä¹Ÿä¸æœƒåƒ KNN ä¸€æ¨£è¢«ç„¡é—œçš„ attribute å½±éŸ¿ã€‚
è€Œä¸Šè¿°ç”± base rule ç”¢ç”Ÿçš„è³‡æ–™æ¯å€‹ attribute éƒ½å­˜åœ¨æ˜ç¢ºçš„åˆ†å‰²é»ï¼Œæ‰€ä»¥æº–ç¢ºç‡æ‰æœƒé«˜é” 1.0ï¼Œä½†**ç•¶ classifaction rule çš„ attributes å½¼æ­¤ä¹‹é–“ä¸å®Œå…¨ç¨ç«‹æ™‚ï¼Œå°‡å¾ˆé›£æœ‰æ•ˆåœ°åˆ‡å‰²**ï¼Œä»¥ä¸‹å°‡å¯¦é©—æŠŠ rule è¨­è¨ˆæˆéœ€è¦å…±åŒè€ƒæ…®å¤šå€‹ attributes æ‰èƒ½åšåˆ†é¡å¾Œï¼Œè§€å¯Ÿå…¶å° accuracy çš„å½±éŸ¿ã€‚

#### 2-1. Attributes ä¹‹é–“éƒ¨ä»½ç›¸ä¾

|          | èº«é«˜       | é«”é‡          | è¦–åŠ›     | æ™ºèƒ½    |
| -------- | ---------- | ------------- | -------- | ------- |
| æ•¸å€¼ç¯„åœ | 140~220    | 30~130        | 2.0~0    | 180~60  |
| å½¹ç”·æ¢ä»¶ | 155<x1<196 | ==16.5<BMI<31.5== | x2 > 0.1 | x3 > 85 |

å°‡ base rule æ“´å¼µå¦‚ä¸Šï¼Œæ–°å¢é«”é‡ä¸€æ¬„ä¸¦ä»¥ BMI (é ˆå…±åŒè€ƒæ…®åˆ°èº«é«˜èˆ‡é«”é‡å…©å€‹ attribute) ä½œç‚ºåˆ¤æ–·æ¨™æº–ï¼Œå†å°‡å¾Œæ–¹æ‰€æœ‰çš„ binary attribute ç§»é™¤å¾Œï¼Œç”±æ­¤ rule é‡æ–°ç”¢ç”Ÿ dataset å¾Œè¡¨ç¾å¦‚ä¸‹ï¼š
```sehll
$ python abs_generator.py --use_bmi True --binary 0
```
- training data accuracy: 0.93
- testing data accuracy: 0.96

å¯ä»¥çœ‹åˆ° accuracy å·²ç¶“ä¸å†æ˜¯ 100%ï¼Œé€™è¡¨ç¤ºå­˜åœ¨ä¸å®Œå…¨ç¨ç«‹çš„ attributes ç¢ºå¯¦æœƒå½±éŸ¿åˆ° decision tree çš„è¡¨ç¾ã€‚

#### 2-2. Attributes å…¨éƒ¨ç›¸ä¾

ç‚ºäº†é€²ä¸€æ­¥æé«˜ attributes ä¹‹é–“çš„ç›¸ä¾æ€§ï¼Œå› æ­¤æˆ‘å°‡ rule ä¸­çš„ binary attributes åŠ å›ä¾†ï¼Œå†å¾åªè¦æ»¿è¶³ä»»ä¸€æ¢ä»¶æ”¹ç‚ºè‡³å°‘é ˆæ»¿è¶³ä¸‰é …æ¢ä»¶æ‰å¯å…å½¹ï¼Œå¦‚æ­¤ä¸€ä¾† classifaction å°±å¿…é ˆ**åŒæ™‚è€ƒæ…®æ‰€æœ‰çš„ attributes** æ‰èƒ½å¤ æ­£ç¢ºåˆ¤æ–·ï¼Œé‡æ–°ç”¢ç”Ÿ dataset å¾Œè¡¨ç¾å¦‚ä¸‹ï¼š
```shell
$ python abs_generator.py --use_bmi True --dependent 3
```
- training data accuracy: 0.88
- testing data accuracy: 0.72

accuracy å†æ¬¡é™ä½äº†ï¼Œé€™å†æ¬¡é©—è­‰ä¸Šè¿°èªªæ³•ä¹‹æ­£ç¢ºï¼Œattributes ä¹‹é–“çš„ç›¸ä¾æ€§è¶Šé«˜ï¼Œdecision tree çš„æ•ˆæœå°‡æœƒè¶Šå·®ã€‚

---

### 3. Random Forest

Decision tree é™¤äº†ä¸Šè¿°å•é¡Œä¹‹å¤–ï¼Œå¾å…¶å°ä¸Šè¿°æœ€å¾Œä¸€å€‹ rule ä¹‹ accuracy åœ¨ training èˆ‡ testing data ä¹‹é–“æœ‰æ˜é¡¯çš„è½å·®ï¼Œå¯çœ‹å‡ºå…¶å­˜åœ¨ overfitting çš„å•é¡Œï¼Œè€Œ random forest é€éç”±å¤šå€‹ decision tree å„åªä½¿ç”¨ä¸€éƒ¨åˆ†çš„ training data å†å…±åŒæ±ºå®šåˆ†é¡çµæœï¼Œä¾†é¿å…æ•´é«” overfitting æ–¼ training data ä¸Šï¼Œé€™é‚ŠåŒæ¨£ä½¿ç”¨ scikit-learn çš„ random forest å¥—ä»¶æ–¼ä¸Šè¿° dataset è¡¨ç¾å¦‚ä¸‹ï¼š
- training data accuracy: 0.90
- testing data accuracy: 0.90

é›–ç„¶æ²’æœ‰åœ¨ training accuracy ä¸Šæœ‰æ˜é¡¯çš„é€²æ­¥ï¼Œä½†èˆ‡ testing accuracy ä¹‹é–“çš„è½å·®ç¢ºå¯¦ä¸‹é™äº†è¨±å¤šï¼Œé€™ä»£è¡¨ random forest ç¢ºå¯¦æœ‰é¿å… overfitting çš„åŠŸæ•ˆã€‚

---

### 4. Naive Bayes

Navie bayes æ˜¯å®Œå…¨å°‡ attribute ç™¼ç”Ÿçš„æ©Ÿç‡è¦–ä½œç¨ç«‹äº‹ä»¶å¾Œï¼Œæ‰¾å‡ºå±¬æ–¼è©²é¡åˆ¥ä¹‹æ©Ÿç‡æœ€é«˜è€…çš„ç®—æ³•ï¼Œåœ¨ base rule ä¸­ç”±æ–¼ attributes ä¹‹é–“æ˜¯å®Œå…¨äº’ç›¸ç¨ç«‹çš„ï¼Œå› æ­¤ naive bayes çš„è¡¨ç¾ç›¸ç•¶ä¸éŒ¯ï¼Œå³ä¾¿ä»¿ç…§ä¸Šæ–¹ KNN çš„ä½œæ³•åŠ å…¥äº†ä¸€äº› irrelevant attributes è¡¨ç¾ä¾èˆŠä¸éŒ¯ï¼Œé€™æ˜¯å› ç‚º irrelevant attributes å°æ–¼æ‰€å±¬é¡åˆ¥çš„æ©Ÿç‡è²¢ç»æœƒå®Œå…¨ç›¸åŒï¼Œä¸¦ä¸æœƒå°æœ€å¾Œçš„é¡åˆ¥åˆ¤æ–·æœ‰å½±éŸ¿ã€‚
ç„¶è€Œï¼Œå‡è¨­ attributes ä¹‹é–“å®Œå…¨äº’ç›¸ç¨ç«‹ä¹Ÿæ˜¯ navie bayes æœ€å¤§çš„ç¼ºé»ï¼Œä»¥ä¸‹åŒæ¨£æœƒå¯¦é©—æŠŠ rule æ’å…¥é«”é‡ä¸€æ¬„ä¸¦å°‡ BMI åŠ å…¥ classifaction rule å¾Œè§€å¯Ÿå…¶å° accuracy çš„å½±éŸ¿ã€‚
- training data accuracy: 0.83
- testing data accuracy: 0.47

å¯ä»¥çœ‹åˆ° accuracy å¤§å¹…é™ä½äº†ï¼Œé©—è­‰äº† naive bayes éå¸¸ä¾è³´ attributes ä¹‹é–“çš„ç¨ç«‹æ€§ã€‚

---

### 5. Linear SVM

Linear SVM çš„ç®—æ³•æ˜¯æ‰¾åˆ°ç·šæ€§é‚Šç•Œä¾†ç›¡å¯èƒ½ä½¿ä»–èˆ‡å…©å€‹ç¾¤çš„æ•´é«”è·é›¢æœ€å¤§åŒ–ï¼Œä½†ç”±æ–¼ä¸Šæ–¹çš„ base rule æœƒå°‡æ¯å€‹ attribute ç¨ç«‹è€ƒæ…®ï¼Œå› æ­¤è©²é‚Šç•Œå¿…å®šæ˜¯éç·šæ€§çš„ï¼Œæ‰€ä»¥åœ¨æ­¤ linear SVM çš„è¡¨ç¾ä¸¦ä¸å¥½ï¼Œä»¥ä¸‹å°‡å¯¦é©—å°‡ classifaction rule æ”¹ç‚º attribute ä¹‹é–“çš„ç·šæ€§çµ„åˆå¾Œè§€å¯Ÿå…¶å° accuracy çš„å½±éŸ¿ã€‚

$$
300 < èº«é«˜ - 100 \times è¦–åŠ› + 2 \times æ™ºå•† < 450
$$

å°‡ rule æ”¹ç‚ºè‹¥è½åœ¨ä¸Šè¿°å…¬å¼çš„ç¯„åœå…§ï¼Œå‰‡ç‚º positive dataï¼Œä¿®æ”¹è¦å‰‡å¾Œè¡¨ç¾å¦‚ä¸‹ï¼š
```shell
$ python abs_generator.py --use_linear True
```
- training data accuracy: 0.91
- testing data accuracy: 0.98

accuracy å¤§å¹…ä¸Šå‡äº†ï¼Œé€™èªªæ˜**è‹¥åˆ†ç¾¤é‚Šç•Œæ˜¯ç·šæ€§çš„ï¼Œlinear SVM æœƒè¡¨ç¾çš„éå¸¸å¥½**ã€‚

## ä¸‰ã€Summary

ä¸‹æ–¹è¡¨æ ¼ç°¡å–®æ•´ç†äº†é€™æ¬¡ project æœ‰å˜—è©¦ä½¿ç”¨çš„æ¨¡å‹åŠå…¶å„ªåŠ£å‹¢ï¼Œå¯ä»¥çœ‹å‡ºåˆ†é¡æ¨¡å‹å„æœ‰å„ªåŠ£ï¼Œä¸¦æ²’æœ‰å“ªä¸€ç¨®æ¨¡å‹çš„è¡¨ç¾å¿…å®šæœƒæœ€å¥½ï¼Œæ‡‰è¦æ ¹æ“šç›®å‰è³‡æ–™çš„ç‰¹æ€§å»æŒ‘é¸åˆé©çš„æ¨¡å‹ï¼Œå› æ­¤åœ¨æ‹¿åˆ°è¦åˆ†é¡çš„è³‡æ–™æ™‚ä¸å¦¨å…ˆå°‡é€™äº›ä¸»æµæ¨¡å‹å…¨éƒ½è©¦éä¸€æ¬¡ï¼Œå¯ä»¥å…ˆæ ¹æ“šå…¶è¡¨ç¾ä¾†å°ç…§é€™å€‹è¡¨æ ¼ï¼Œç°¡å–®æ­¸ç´å‡ºè³‡æ–™çš„ç‰¹æ€§å¾Œå†ç¹¼çºŒå¾ŒçºŒçš„è™•ç†ã€‚

|               | å„ªå‹¢                                        | åŠ£å‹¢                                     |
| ------------- | ------------------------------------------- | ---------------------------------------- |
| KNN           | ç°¡å–®æ˜“ç”¨                                    | ç„¡æ³•åˆ¤åˆ¥ feature çš„é‡è¦æ€§                |
| Decision Tree | è‡ªå‹•æ‰¾å‡ºæœ‰ç”¨çš„ feature                      | å®¹æ˜“ overfittingã€ä¸å¥½è™•ç†éç¨ç«‹ feature |
| Random Forest | å¤§å¹…æ”¹é€²äº† decision tree overfitting çš„å•é¡Œ | é‚„æ˜¯ä¸å¥½è™•ç†éç¨ç«‹ feature               |
| Naive Bayes   | è‡ªå‹•æ‰¾å‡ºæœ‰ç”¨çš„ feature                      | ä¸å¥½è™•ç†éç¨ç«‹ feature                   |
| Linear SVM    | å®¹æ˜“è™•ç†ç·šæ€§åˆ†é¡è¦å‰‡                        | boundary éç·šæ€§æ™‚ç„¡æ³•åˆ†å‰²                |
